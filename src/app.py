import gradio as gr
import joblib
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from itertools import combinations
import re

# --- 1. CONFIG & T·∫¢I C√ÅC MODEL C·∫¶N THI·∫æT (CH·ªà T·∫¢I M·ªòT L·∫¶N) ---

# √Ånh x·∫° MBTI sang vai tr√≤ g·ª£i √Ω
MBTI_ROLE_MAP = {
    "ENTJ": "Leader / Coordinator", "ESTJ": "Leader / Coordinator",
    "INTJ": "Planner / Architect", "ISTJ": "Planner / Architect",
    "ENTP": "Ideator / Strategist", "INTP": "Ideator / Strategist",
    "ENFJ": "Coach / Mediator", "INFJ": "Coach / Mediator",
    "ESFJ": "Facilitator / Operations", "ISFJ": "Facilitator / Operations",
    "ESFP": "Energizer / UX & Content", "ISFP": "Energizer / UX & Content",
    "ESTP": "Troubleshooter / Executor", "ISTP": "Troubleshooter / Executor",
    "ENFP": "Storyteller / Community", "INFP": "Storyteller / Community"
}

# Th√™m l·ªùi gi·∫£i th√≠ch cho t·ª´ng vai tr√≤
ROLE_EXPLANATIONS = {
    "Leader / Coordinator": "**Nh√≥m Leader/Coordinator (ENTJ, ESTJ):** Gi·ªèi ƒë·ªãnh h∆∞·ªõng, l·∫≠p k·∫ø ho·∫°ch v√† ƒëi·ªÅu ph·ªëi ngu·ªìn l·ª±c. H·ªç l√† nh·ªØng ng∆∞·ªùi thuy·ªÅn tr∆∞·ªüng, d·∫´n d·∫Øt ƒë·ªôi nh√≥m ƒëi ƒë√∫ng h∆∞·ªõng.",
    "Planner / Architect": "**Nh√≥m Planner/Architect (INTJ, ISTJ):** C√≥ t∆∞ duy chi·∫øn l∆∞·ª£c, kh·∫£ nƒÉng x√¢y d·ª±ng h·ªá th·ªëng v√† k·∫ø ho·∫°ch d√†i h·∫°n. H·ªç l√† nh·ªØng ki·∫øn tr√∫c s∆∞ c·ªßa d·ª± √°n.",
    "Ideator / Strategist": "**Nh√≥m Ideator/Strategist (ENTP, INTP):** S√°ng t·∫°o, th√≠ch kh√°m ph√° √Ω t∆∞·ªüng m·ªõi v√† t√¨m ra c√°c gi·∫£i ph√°p ƒë·ªôc ƒë√°o cho nh·ªØng v·∫•n ƒë·ªÅ ph·ª©c t·∫°p.",
    "Coach / Mediator": "**Nh√≥m Coach/Mediator (ENFJ, INFJ):** Th·∫•u c·∫£m, c√≥ kh·∫£ nƒÉng truy·ªÅn c·∫£m h·ª©ng, ph√°t tri·ªÉn ti·ªÅm nƒÉng con ng∆∞·ªùi v√† gi·∫£i quy·∫øt xung ƒë·ªôt n·ªôi b·ªô.",
    "Facilitator / Operations": "**Nh√≥m Facilitator/Operations (ESFJ, ISFJ):** Th·ª±c t·∫ø, ch√∫ tr·ªçng chi ti·∫øt v√† gi·ªèi h·ªó tr·ª£, ƒë·∫£m b·∫£o quy tr√¨nh v·∫≠n h√†nh tr∆°n tru v√† m·ªçi ng∆∞·ªùi ƒë∆∞·ª£c k·∫øt n·ªëi.",
    "Energizer / UX & Content": "**Nh√≥m Energizer/UX & Content (ESFP, ISFP):** Mang l·∫°i nƒÉng l∆∞·ª£ng t√≠ch c·ª±c, c√≥ gu th·∫©m m·ªπ t·ªët, ph√π h·ª£p v·ªõi c√°c vai tr√≤ li√™n quan ƒë·∫øn tr·∫£i nghi·ªám ng∆∞·ªùi d√πng v√† s√°ng t·∫°o n·ªôi dung.",
    "Troubleshooter / Executor": "**Nh√≥m Troubleshooter/Executor (ESTP, ISTP):** Linh ho·∫°t, ph·∫£n ·ª©ng nhanh v√† gi·ªèi gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ ph√°t sinh t·ª©c th·ªùi. H·ªç l√† nh·ªØng ng∆∞·ªùi th·ª±c thi hi·ªáu qu·∫£.",
    "Storyteller / Community": "**Nh√≥m Storyteller/Community (ENFP, INFP):** Gi·ªèi truy·ªÅn t·∫£i th√¥ng ƒëi·ªáp, x√¢y d·ª±ng c√¢u chuy·ªán v√† k·∫øt n·ªëi c·ªông ƒë·ªìng. H·ªç l√† linh h·ªìn c·ªßa ƒë·ªôi nh√≥m."
}


# T·∫£i m√¥ h√¨nh embedding
print("ƒêang t·∫£i Sentence Transformer model...")
encoder_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
print("T·∫£i xong Sentence Transformer model.")

# T·∫£i 4 m√¥ h√¨nh classifier ƒë√£ hu·∫•n luy·ªán
classifiers = {}
dimensions = ["IE", "NS", "TF", "JP"]
for dim in dimensions:
    try:
        model_path = f"models/clf_{dim}.joblib"
        classifiers[dim] = joblib.load(model_path)
        print(f"ƒê√£ t·∫£i classifier cho: {dim}")
    except FileNotFoundError:
        print(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file {model_path}. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ hu·∫•n luy·ªán v√† l∆∞u model.")
        exit()

# √Ånh x·∫° nh√£n 0/1 sang ch·ªØ c√°i
LABEL_MAP = {
    "IE": {0: "I", 1: "E"},
    "NS": {0: "N", 1: "S"},
    "TF": {0: "T", 1: "F"},
    "JP": {0: "J", 1: "P"}
}

# --- 2. H√ÄM X·ª¨ L√ù LOGIC CH√çNH ---

def get_explanation(text, dimension):
    """
    L·∫•y 2-3 t·ª´ kh√≥a ·∫£nh h∆∞·ªüng nh·∫•t b·∫±ng ph∆∞∆°ng ph√°p Leave-One-Out (nhanh h∆°n LIME).
    """
    try:
        clf = classifiers[dimension]
        
        # 1. L·∫•y x√°c su·∫•t g·ªëc
        original_embedding = encoder_model.encode([text])
        original_proba = clf.predict_proba(original_embedding)[0]
        predicted_class_index = np.argmax(original_proba)
        original_confidence = original_proba[predicted_class_index]

        # 2. T√°ch vƒÉn b·∫£n th√†nh c√°c t·ª´ duy nh·∫•t
        words = list(set(re.findall(r'\b\w+\b', text.lower())))
        if not words: return "Kh√¥ng c√≥ t·ª´ ƒë·ªÉ ph√¢n t√≠ch"

        # 3. T√≠nh to√°n s·ª± thay ƒë·ªïi khi b·ªè ƒëi t·ª´ng t·ª´
        word_impacts = {}
        for word in words:
            # T·∫°o vƒÉn b·∫£n m·ªõi kh√¥ng c√≥ t·ª´ hi·ªán t·∫°i
            temp_text = ' '.join([w for w in text.lower().split() if w != word])
            if not temp_text: continue
            
            temp_embedding = encoder_model.encode([temp_text])
            new_proba = clf.predict_proba(temp_embedding)[0]
            new_confidence = new_proba[predicted_class_index]
            
            # T√°c ƒë·ªông l√† s·ª± s·ª•t gi·∫£m c·ªßa ƒë·ªô tin c·∫≠y
            impact = original_confidence - new_confidence
            word_impacts[word] = impact

        # 4. S·∫Øp x·∫øp v√† l·∫•y 3 t·ª´ c√≥ t√°c ƒë·ªông l·ªõn nh·∫•t
        if not word_impacts: return "Kh√¥ng th·ªÉ t·∫°o gi·∫£i th√≠ch"
            
        sorted_words = sorted(word_impacts.items(), key=lambda item: item[1], reverse=True)
        top_words = [word for word, impact in sorted_words[:3]]
        
        return ", ".join(f"'{word}'" for word in top_words)
    except Exception as e:
        print(f"L·ªói khi t·∫°o gi·∫£i th√≠ch cho {dimension}: {e}")
        return "Kh√¥ng th·ªÉ t·∫°o gi·∫£i th√≠ch"


def hamming_distance(mbti1, mbti2):
    """T√≠nh kho·∫£ng c√°ch Hamming gi·ªØa 2 chu·ªói MBTI."""
    return sum(c1 != c2 for c1, c2 in zip(mbti1, mbti2))

def get_team_suggestions(result_df):
    """
    Thu·∫≠t to√°n tham lam ƒë·ªÉ g·ª£i √Ω ƒë·ªôi nh√≥m d·ª±a tr√™n k·∫øt qu·∫£ d·ª± ƒëo√°n.
    """
    if len(result_df) < 4:
        return "C·∫ßn √≠t nh·∫•t 4 th√†nh vi√™n ƒë·ªÉ c√≥ th·ªÉ ƒë∆∞a ra g·ª£i √Ω ƒë·ªôi nh√≥m t·ªëi ∆∞u.", ""

    # --- Tri·ªÉn khai gi·∫£i ph√°p tham lam ---
    members = result_df.to_dict('records')
    
    # T√≠nh t·ªïng ƒë·ªô tin c·∫≠y cho m·ªói th√†nh vi√™n
    for member in members:
        member['total_confidence'] = sum(
            float(member[f'ƒê·ªô tin c·∫≠y ({dim})'].strip('%'))
            for dim in dimensions
        )

    # S·∫Øp x·∫øp th√†nh vi√™n theo ƒë·ªô tin c·∫≠y gi·∫£m d·∫ßn
    members.sort(key=lambda x: x['total_confidence'], reverse=True)
    
    # B·∫Øt ƒë·∫ßu v·ªõi ng∆∞·ªùi c√≥ ƒë·ªô tin c·∫≠y cao nh·∫•t
    optimal_team = [members.pop(0)]
    
    # Th√™m 3 th√†nh vi√™n ti·∫øp theo ƒë·ªÉ t·ªëi ƒëa h√≥a s·ª± ƒëa d·∫°ng
    while len(optimal_team) < 4 and members:
        best_candidate = None
        max_diversity_score = -1
        
        for candidate in members:
            current_diversity_score = sum(
                hamming_distance(candidate['MBTI D·ª± ƒëo√°n'], team_member['MBTI D·ª± ƒëo√°n'])
                for team_member in optimal_team
            )
            if current_diversity_score > max_diversity_score:
                max_diversity_score = current_diversity_score
                best_candidate = candidate
        
        if best_candidate:
            optimal_team.append(best_candidate)
            members.remove(best_candidate)
            
    # --- ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ƒë·∫ßu ra ---
    team_roles = [m['Vai tr√≤ g·ª£i √Ω'].split(' / ')[0] for m in optimal_team] # L·∫•y vai tr√≤ ch√≠nh
    
    # Ki·ªÉm tra r√†ng bu·ªôc vai tr√≤
    required_roles = {"Leader", "Planner", "Executor", "Facilitator"}
    present_roles = set(team_roles)
    missing_roles = required_roles - present_roles
    
    # T·∫°o chu·ªói k·∫øt qu·∫£
    suggestion_text = "### ü§ù ƒê·ªôi nh√≥m g·ª£i √Ω (T·ªëi ∆∞u cho s·ª± ƒëa d·∫°ng)\n\n"
    for member in optimal_team:
        suggestion_text += f"- **{member['Th√†nh vi√™n']}:** {member['MBTI D·ª± ƒëo√°n']} ({member['Vai tr√≤ g·ª£i √Ω']})\n"
        
    suggestion_text += "\n**Ph√¢n t√≠ch ƒë·ªôi nh√≥m:**\n"
    if not missing_roles:
        suggestion_text += "‚úÖ ƒê·ªôi nh√≥m n√†y c√¢n b·∫±ng, ƒë√£ c√≥ ƒë·ªß c√°c vai tr√≤ c·ªët l√µi: Leader, Planner, Executor, Facilitator.\n"
    else:
        suggestion_text += f"‚ö†Ô∏è **L∆∞u √Ω:** ƒê·ªôi nh√≥m n√†y ƒëang thi·∫øu c√°c vai tr√≤: **{', '.join(missing_roles)}**. C√¢n nh·∫Øc b·ªï sung th√†nh vi√™n c√≥ c√°c vai tr√≤ n√†y.\n"

    # Th√™m gi·∫£i th√≠ch vai tr√≤
    explanation_text = "### üìñ Gi·∫£i th√≠ch c√°c vai tr√≤ c√≥ trong ƒë·ªôi\n\n"
    unique_roles_in_team = {m['Vai tr√≤ g·ª£i √Ω'] for m in optimal_team}
    for role in unique_roles_in_team:
        if role in ROLE_EXPLANATIONS:
            explanation_text += ROLE_EXPLANATIONS[role] + "\n\n"
            
    return suggestion_text, explanation_text


def process_team_builder(*args):
    """
    H√†m t·ªïng h·ª£p: nh·∫≠n (t√™n, vƒÉn b·∫£n) -> d·ª± ƒëo√°n -> gi·∫£i th√≠ch -> g·ª£i √Ω ƒë·ªôi nh√≥m.
    """
    members_data = []
    
    # args l√† m·ªôt list ph·∫≥ng: [name1, text1, name2, text2, ...]
    names = args[0::2] # L·∫•y t·∫•t c·∫£ c√°c t√™n
    texts = args[1::2] # L·∫•y t·∫•t c·∫£ c√°c vƒÉn b·∫£n

    for i, (name, text) in enumerate(zip(names, texts)):
        if not text.strip(): continue
        
        print(f"ƒêang x·ª≠ l√Ω Th√†nh vi√™n {i+1}...")
        
        # Quy·∫øt ƒë·ªãnh t√™n th√†nh vi√™n
        member_name = name.strip() if name.strip() else f"Ng∆∞·ªùi {i+1}"

        embedding = encoder_model.encode([text])
        mbti_type = ""
        confidences = {}
        explanations = ""
        
        for dim in dimensions:
            # D·ª± ƒëo√°n
            clf = classifiers[dim]
            pred_label = clf.predict(embedding)[0]
            pred_proba = clf.predict_proba(embedding)[0]
            confidence = pred_proba[pred_label]
            mbti_char = LABEL_MAP[dim][pred_label]
            mbti_type += mbti_char
            confidences[dim] = f"{confidence*100:.2f}%"

            # L·∫•y gi·∫£i th√≠ch
            explanation_words = get_explanation(text, dim)
            explanations += f"**{mbti_char}** v√¨: {explanation_words}\n"


        role = MBTI_ROLE_MAP.get(mbti_type, "Ch∆∞a x√°c ƒë·ªãnh")
        
        member_info = {
            "Th√†nh vi√™n": member_name,
            "MBTI D·ª± ƒëo√°n": mbti_type,
            "Vai tr√≤ g·ª£i √Ω": role,
            "T·ª´ kh√≥a ·∫£nh h∆∞·ªüng": explanations.strip()
        }
        for dim in dimensions:
            member_info[f"ƒê·ªô tin c·∫≠y ({dim})"] = confidences[dim]
        
        members_data.append(member_info)

    if not members_data:
        return pd.DataFrame(), "Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c·ªßa √≠t nh·∫•t m·ªôt th√†nh vi√™n.", ""

    # S·∫Øp x·∫øp l·∫°i th·ª© t·ª± c·ªôt cho ƒë·∫πp m·∫Øt
    column_order = [
        "Th√†nh vi√™n", "MBTI D·ª± ƒëo√°n", "Vai tr√≤ g·ª£i √Ω", 
        "ƒê·ªô tin c·∫≠y (IE)", "ƒê·ªô tin c·∫≠y (NS)", "ƒê·ªô tin c·∫≠y (TF)", "ƒê·ªô tin c·∫≠y (JP)",
        "T·ª´ kh√≥a ·∫£nh h∆∞·ªüng"
    ]
    result_df = pd.DataFrame(members_data)[column_order]
    
    print("ƒê√£ x·ª≠ l√Ω xong. ƒêang t·∫°o g·ª£i √Ω ƒë·ªôi nh√≥m...")
    suggestion_text, explanation_text = get_team_suggestions(result_df)
    
    return result_df, suggestion_text, explanation_text

# --- 3. T·∫†O GIAO DI·ªÜN WEB V·ªöI GRADIO ---

APP_DESCRIPTION = """
## Ch√†o m·ª´ng ƒë·∫øn v·ªõi AI Team Builder!
1.  **Nh·∫≠p th√¥ng tin:** ƒêi·ªÅn t√™n (t√πy ch·ªçn) v√† d√°n m·ªôt ƒëo·∫°n vƒÉn b·∫£n (ti·∫øng Anh) c·ªßa m·ªói th√†nh vi√™n v√†o c√°c √¥ b√™n d∆∞·ªõi. C·∫ßn √≠t nh·∫•t 4 th√†nh vi√™n ƒë·ªÉ c√≥ g·ª£i √Ω ƒë·ªôi nh√≥m.
2.  **Nh·∫•n "G·ª£i √Ω ƒë·ªôi nh√≥m":** AI s·∫Ω d·ª± ƒëo√°n MBTI, sau ƒë√≥ ƒë·ªÅ xu·∫•t m·ªôt ƒë·ªôi h√¨nh t·ªëi ∆∞u v·ªÅ s·ª± ƒëa d·∫°ng v√† c√¢n b·∫±ng vai tr√≤.
3.  **Xem k·∫øt qu·∫£:** Xem b·∫£ng ph√¢n t√≠ch chi ti·∫øt v√† c√°c g·ª£i √Ω ƒë·ªôi nh√≥m b√™n d∆∞·ªõi.

**L∆∞u √Ω v·ªÅ ƒë·∫°o ƒë·ª©c:** C√¥ng c·ª• n√†y ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o. K·∫øt qu·∫£ d·ª± ƒëo√°n kh√¥ng ph·∫£i l√† m·ªôt ph√°n quy·∫øt v·ªÅ con ng∆∞·ªùi v√† kh√¥ng n√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng cho c√°c quy·∫øt ƒë·ªãnh quan tr·ªçng nh∆∞ tuy·ªÉn d·ª•ng. Ch√∫ng t√¥i kh√¥ng l∆∞u l·∫°i b·∫•t k·ª≥ vƒÉn b·∫£n n√†o b·∫°n nh·∫≠p v√†o.
"""

NUM_MEMBERS = 5

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üöÄ AI Team Builder Prototype")
    gr.Markdown(APP_DESCRIPTION)

    inputs = []
    with gr.Row():
        for i in range(NUM_MEMBERS):
            with gr.Column():
                name_input = gr.Textbox(
                    label=f"T√™n Th√†nh vi√™n {i+1}", 
                    placeholder=f"T√πy ch·ªçn (m·∫∑c ƒë·ªãnh: Ng∆∞·ªùi {i+1})"
                )
                text_input = gr.Textbox(
                    label=f"VƒÉn b·∫£n c·ªßa Th√†nh vi√™n {i+1}", 
                    lines=6, 
                    placeholder="D√°n vƒÉn b·∫£n v√†o ƒë√¢y..."
                )
                inputs.append(name_input)
                inputs.append(text_input)
    
    submit_button = gr.Button("G·ª£i √Ω ƒë·ªôi nh√≥m", variant="primary")
    
    gr.Markdown("---")
    
    with gr.Row():
        with gr.Column(scale=3): # TƒÉng ƒë·ªô r·ªông c·ªôt b·∫£ng
            gr.Markdown("## üìä B·∫£ng ph√¢n t√≠ch chi ti·∫øt")
            output_dataframe = gr.DataFrame(label="K·∫øt qu·∫£")
        with gr.Column(scale=1):
            gr.Markdown("## üí° G·ª£i √Ω & Gi·∫£i th√≠ch")
            output_suggestion = gr.Markdown(label="G·ª£i √Ω ƒë·ªôi nh√≥m")
            output_explanation = gr.Markdown(label="Gi·∫£i th√≠ch vai tr√≤")


    submit_button.click(
        fn=process_team_builder,
        inputs=inputs,
        outputs=[output_dataframe, output_suggestion, output_explanation],
        show_progress="full" # Th√™m thanh ti·∫øn tr√¨nh
    )

# --- 4. CH·∫†Y ·ª®NG D·ª§NG ---
if __name__ == "__main__":
    demo.launch()

